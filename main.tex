\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\geometry{a4paper, margin=2cm}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{hyperref}
\onehalfspacing

\title{Создание ML-классификатора переменных звёзд}
\author{Нигматуллин Амир, Ломака Арсений, Данилов Андрей \\ Научная студия Центрального университета}
\date{Декабрь 2025}

\begin{document}

\maketitle

\section{Введение}

Переменные звёзды - астрономические объекты, чья видимая яркость со временем изменяется. Их изучение играет ключевую роль в понимании звёздной эволюции, структуры галактики и космологических расстояний. Современные обзоры неба генерируют огромные объёмы фотометрических данных, что делает ручную идентификацию переменных звёзд неэффективной. Подходы машинного обучения (ML) позволяют автоматизировать этот процесс, используя магнитуды в различных диапазонах и производные признаки (например, цветовые индексы и амплитуду изменений блеска). В данной работе на основе открытых данных строится и сравнивается несколько ML-моделей для решения задачи бинарной классификации: «переменная звезда / не переменная».

Актуальность исследования обусловлена быстрым ростом объёмов астрономических данных из обзоров, таких как Gaia и предстоящий LSST, где количество объектов достигает миллиардов, а доля переменных звёзд остаётся малой (менее 1\%). Традиционные методы классификации, опирающиеся на анализ полных световых кривых, требуют многократных наблюдений и значительных вычислительных ресурсов, что делает их неприменимыми для предварительного скрининга больших каталогов~\cite{debosscher2007}. Современные работы часто фокусируются на классификации подтипов переменных с использованием временных рядов и нейронных сетей, таких как CNN или LSTM~\cite{naul2018, li2024}, или ансамблей на основе деревьев для детализированных данных Kepler~\cite{armstrong2016}. 

Однако существует ниша в разработке эффективных методов на основе статических фотометрических признаков (магнитуды и цветовые индексы без временной зависимости), которые позволяют быстро отбирать кандидатов из объединённых каталогов, минимизируя ложные срабатывания и пропуски в условиях сильного дисбаланса классов~\cite{becker2020, wang2025, liu2024}. Многие исследования подчеркивают проблему дисбаланса, решая её через oversampling, undersampling или иерархические схемы~\cite{becker2020, liu2024}, но реже применяют каскадные подходы для бинарной задачи, где сначала максимизируется полнота, а затем точность. Наша работа заполняет эту нишу, предлагая каскадную схему для баланса между полнотой и точностью, что особенно полезно для предварительного анализа в крупных обзорах, снижая нагрузку на ученых и повышая надёжность последующих исследований.

Практическая значимость работы заключается в том, что разработанный классификатор может быть интегрирован в пайплайны обработки данных астрономических обсерваторий, позволяя автоматизировать отбор кандидатов на переменные звёзды. Это не только ускорит научные открытия, но и сделает анализ доступным для меньших команд без мощных вычислительных ресурсов, способствуя более широкому использованию ML в астрономии.

Целью исследования является разработка оптимального алгоритма бинарной классификации переменных звезд при условии сильного дисбаланса классов на основе многодиапазонной фотометрии и простых статистических признаков. Для достижения цели в рамках работы были собраны и агрегированы данные, а также проверены устойчивость и качество алгоритмов машинного обучения. 


\section{Данные и предобработка}

Для достижения цели работы использовался объединённый каталог фотометрических данных, содержащий измерения магнитуд в различных спектральных диапазонах для 56\,298 объектов. Данные включают как переменные, так и непеременные звёзды, с сильным дисбалансом классов (переменные составляют около 10\%). Предобработка включала удаление пропусков, нормализацию и создание производных признаков: цветовых индексов (разностей магнитуд между диапазонами) и амплитуды блеска (разница между максимальной и минимальной магнитудой). Это позволило расширить пространство признаков до 22 параметров, делая модели более информативными.

Для наглядности приведена таблица описательных статистик финального датасета после предобработки. Она иллюстрирует распределение ключевых признаков, помогая понять структуру данных и потенциальные аномалии.

\begin{table}[H]
\centering
\caption{Описательная статистика основных фотометрических признаков.}
\label{tab:basic_features}
\begin{tabular}{lrrrrrrr}
\toprule
& Vmag & Bmag & gpmag & rpmag & ipmag & fuv\_mag & nuv\_mag \\
\midrule
count & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 \\
mean & 12.972 & 13.570 & 13.236 & 12.820 & 12.686 & 22.081 & 17.314 \\
std & 1.681 & 1.746 & 1.704 & 1.661 & 1.636 & 1.740 & 1.873 \\
min & 6.189 & 6.673 & 6.673 & 5.741 & 4.557 & 11.961 & 11.226 \\
25\% & 11.690 & 12.257 & 11.936 & 11.552 & 11.447 & 21.392 & 16.085 \\
50\% & 12.805 & 13.350 & 13.039 & 12.675 & 12.566 & 22.599 & 17.024 \\
75\% & 14.267 & 14.824 & 14.508 & 14.127 & 13.978 & 23.299 & 18.198 \\
max & 17.174 & 18.432 & 17.630 & 17.034 & 17.016 & 24.849 & 24.182 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Описательная статистика производных признаков: ошибки измерений, метки, экстремумы блеска и основные цветовые индексы.}
\label{tab:derived_features}
\begin{tabular}{lrrrrrrrr}
\toprule
& err & present & min\_mag & max\_mag & V-B & V-gp & V-rp & V-ip \\
\midrule
count & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 \\
mean & 0.174 & 0.105 & 13.080 & 9.836 & -0.597 & -0.264 & 0.152 & 0.286 \\
std & 0.171 & 0.307 & 1.580 & 5.819 & 0.243 & 0.147 & 0.116 & 0.278 \\
min & 0.014 & 0.000 & 6.150 & 0.001 & -2.036 & -1.962 & -2.149 & -2.321 \\
25\% & 0.089 & 0.000 & 12.070 & 0.802 & -0.664 & -0.314 & 0.098 & 0.171 \\
50\% & 0.127 & 0.000 & 13.220 & 12.670 & -0.548 & -0.237 & 0.132 & 0.245 \\
75\% & 0.189 & 0.000 & 14.190 & 13.880 & -0.470 & -0.184 & 0.180 & 0.343 \\
max & 3.579 & 1.000 & 19.600 & 20.470 & 0.781 & 1.035 & 1.421 & 3.933 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Описательная статистика остальных цветовых индексов.}
\label{tab:color_amplitude}
\begin{tabular}{lrrrrrrrr}
\toprule
& V-fuv & V-nuv & B-gp & B-rp & B-ip & gp-rp & gp-ip & fuv-nuv\\
\midrule
count & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00 & 56298.00\\
mean & -9.108 & -4.342 & 0.333 & 0.749 & 0.883 & -8.511 & -3.745 & 4.766 \\
std & 2.314 & 1.221 & 0.126 & 0.350 & 0.501 & 2.302 & 1.055 & 1.963\\
min & -15.849 & -10.749 & -1.513 & -1.553 & -1.924 & -14.638 & -9.126 & -1.496\\
25\% & -10.731 & -4.885 & 0.276 & 0.573 & 0.648 & -10.151 & -4.213 & 3.669\\
50\% & -9.532 & -4.176 & 0.316 & 0.677 & 0.788 & -8.980 & -3.630 & 5.414\\
75\% & -7.901 & -3.659 & 0.369 & 0.836 & 0.990 & -7.314 & -3.178 & 6.259\\
max & 2.404 & 1.503 & 1.261 & 2.571 & 4.894 & 2.075 & 1.174 & 8.678\\
\bottomrule
\end{tabular}
\end{table}


Данные были разделены на обучающую (70\%) и тестовую (30\%) выборки, с сохранением пропорций классов для адекватной оценки моделей в условиях дисбаланса.

\newpage



\section{Базовые модели}
Decision Tree представляет собой интерпретируемую модель, строящую правила в виде дерева. Она чувствительна к шуму, но не требует нормализации данных и легко визуализируется. Random Forest - это ансамбль из множества деревьев, уменьшающий переобучение за счёт усреднения и случайного отбора признаков, что делает его устойчивым к выбросам. Gradient Boosting реализует метод последовательного улучшения предсказаний, где каждая новая модель обучается на ошибках предыдущей, обеспечивая высокую точность. XGBoost - оптимизированная и регуляризованная версия градиентного бустинга, часто показывающая высокие результаты в соревнованиях по машинному обучению благодаря встроенной обработке пропусков и параллелизации. CatBoost - продвинутый вариант градиентного бустинга, специализированный на работе с категориальными признаками и автоматической обработке дисбаланса классов.

Для всех моделей проводился подбор гиперпараметров при помощи кросс-валидации с целевой метрикой F1-score. Выбор F1-score обусловлен необходимостью баланса между  precision и recall в условиях сильного дисбаланса классов. F1-score гармонически объединяет оба аспекта, что делает её оптимальной для оценки качества классификации в данном исследовании. Ниже приведены диапазоны гиперпараметров, участвовавших в поиске. Подбор осуществлялся с помощью GridSearchCV, что обеспечило систематический перебор и выбор оптимальных конфигураций.
\begin{table}[h]
\centering
\caption{Диапазоны перебора гиперпараметров}
\begin{tabular}{@{}ll@{}}
\toprule
Модель & Гиперпараметры \\
\midrule
Decision Tree &
\begin{tabular}[t]{@{}l@{}}
\texttt{max\_depth}: [5, 8, 10, None], \\
\texttt{min\_samples\_split}: [2, 5, 10], \\
\texttt{min\_samples\_leaf}: [1, 2, 4]
\end{tabular} \\
\addlinespace
Random Forest &
\begin{tabular}[t]{@{}l@{}}
\texttt{n\_estimators}: [200, 300], \\
\texttt{max\_depth}: [None, 10, 15], \\
\texttt{min\_samples\_split}: [2, 5], \\
\texttt{min\_samples\_leaf}: [1, 2]
\end{tabular} \\
\addlinespace
Gradient Boosting &
\begin{tabular}[t]{@{}l@{}}
\texttt{n\_estimators}: [200, 300], \\
\texttt{learning\_rate}: [0.05, 0.1], \\
\texttt{max\_depth}: [3, 5]
\end{tabular} \\
\addlinespace
XGBoost &
\begin{tabular}[t]{@{}l@{}}
\texttt{n\_estimators}: [200, 300], \\
\texttt{max\_depth}: [4, 6], \\
\texttt{learning\_rate}: [0.05, 0.1]
\end{tabular} \\
\addlinespace
CatBoost &
\begin{tabular}[t]{@{}l@{}}
\texttt{iterations}: [300, 500], \\
\texttt{depth}: [6, 8], \\
\texttt{learning\_rate}: [0.05, 0.1], \\
\texttt{l2\_leaf\_reg}: [3, 5]
\end{tabular} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Лучшие гиперпараметры, найденные GridSearchCV}
\label{tab:best-params}
\begin{tabular}{lp{9cm}}
\toprule
Модель              & Лучшие параметры \\
\midrule
Decision Tree       & max\_depth=None, min\_samples\_leaf=4, 
                      min\_samples\_split=10 \\
\midrule
Random Forest       & n\_estimators=300, max\_depth=None, 
                      min\_samples\_leaf=1, min\_samples\_split=2 \\
\midrule
Gradient Boosting   & n\_estimators=300, learning\_rate=0.1, 
                      max\_depth=5 \\
\midrule
XGBoost             & n\_estimators=300, learning\_rate=0.1, max\_depth=6, \\
                    & scale\_pos\_weight = 9 \\
\midrule
CatBoost            & n\_estimators=500, learning\_rate=0.1, max\_depth=8, \\
                   
\bottomrule
\end{tabular}
\end{table}

\includegraphics[width=0.9\linewidth]{feature_importance.png}
\caption{Важность признаков по модели CatBoost}
\label{fig:feature_importance}

После обучения моделей мы выявили наиболее важные признаки с помощью встроенного механизма CatBoost, который рассчитывает значимость каждого признака на основе вклада в изменение предсказаний модели. Это позволяет понять, какие параметры данных наиболее информативны для различия переменных и непеременных звёзд. Выше приведён график важности признаков для CatBoost, где по оси Y отложены названия признаков, а по оси X - их относительная значимость в процентах.

Ключевую роль играют минимальная магнитуда \texttt{min\_mag} и цветовой индекс \texttt{rpmag}. Минимальная магнитуда отражает наименьшую наблюдаемую яркость звезды в процессе изучения, что особенно важно для переменных объектов: у них блеск может существенно падать из-за затмений, пульсаций или других физических процессов, в то время как у постоянных звёзд этот параметр остаётся стабильным. Цветовой индекс rpmag характеризует спектральный тип и температуру звезды. Переменные звёзды, такие как цефеиды или RR Лиры, часто имеют характерные цветовые сдвиги из-за изменений в атмосфере или окружении.

\section{Сравнение базовых моделей}
Все модели оценивались на независимой тестовой выборке (16 889 объектов, из которых 1773 - переменные звёзды). В условиях сильного дисбаланса классов (доля положительного класса - 10\%) стандартная метрика accuracy оказывается неинформативной: даже тривиальная модель, предсказывающая всем объектам «постоянная звезда», получит accuracy равный 0.9. \\ Поэтому для сравнения использовались метрики, устойчивые к дисбалансу:\\
Precision (точность, чистота выборки) - доля реальных переменных среди всех объектов, которым модель присвоила класс «переменная».\\
Recall (полнота) - доля найденных переменных звёзд от их общего числа в выборке.\\
F1-score - гармоническое среднее precision и recall, основная целевая метрика исследования.\\
В астрономическом контексте эти метрики имеют прямую практическую интерпретацию:
Высокий precision важен, чтобы не нагружать ученых сотнями ложных кандидатов.
Высокий recall критически важен на этапе предварительного скрининга, чтобы не пропустить редкие и ценные переменные объекты (например, цефеиды, RR Лиры)

\begin{table}[h]
\centering
\caption{Сравнение моделей}
\begin{tabular}{lcccc}
\toprule
Модель & Accuracy & Precision & Recall & F1-score \\
\midrule
CatBoost & 0.9415 & 0.6613 & \textbf{0.9075} & \textbf{0.7651} \\
XGBoost & 0.9287 & 0.6118 & 0.8782 & 0.7212 \\
Gradient Boosting & 0.9400 & 0.7987 & 0.5730 & 0.6673 \\
Random Forest & 0.9285 & \textbf{0.8291} & 0.4021 & 0.5416 \\
Decision Tree & 0.8992 & 0.5222 & 0.4704 & 0.4950 \\
\bottomrule
\end{tabular}
\end{table}

\newpage
\section{Каскад моделей}
Для улучшения качества классификации в условиях сильного дисбаланса классов мы решили применить каскадную схему, позволяющую комбинировать сильные стороны различных моделей. Идея заключается в двухэтапном подходе: на первом этапе модель с высоким recall отбирает максимально широкий круг кандидатов в переменные звёзды, а на втором модель с высоким precision уточняет предсказания, снижая число ложных срабатываний.

Первоначально мы протестировали комбинацию CatBoost (recall = 0.9075) в паре с Gradient Boosting (precision = 0.7987), а также CatBoost с XGBoost (recall = 0.8782). Однако эти варианты не принесли заметного улучшения метрик: F1-score оставалась на уровне базовых моделей, а в некоторых случаях даже снижался.
Небольшого улучшения удалось достичь с помощью каскада, где дважды применяется CatBoost с различными настройками порога вероятности. На первом этапе CatBoost отбирает кандидатов с низким порогом (для максимизации recall), а на втором - уточняет их с повышенным порогом (для роста precision). На тестовой выборке (1773 реальных переменных) схема отобрала 2430 кандидатов, из которых 1608 оказались верными, обеспечив следующие метрики: precision = 0.7241, recall = 0.8511, F1-score = 0.7825. Это соответствует приросту F1-score на 0.0174 по сравнению с одиночным CatBoost (с 0.7651 до 0.7825).


\begin{table}[h]
\centering
\caption{Итоговые метрики каскада}
\begin{tabular}{lcc}
\toprule
Метрика & Значение\\
\midrule
Precision & 0.7241\\
Recall & 0.8511\\
F1-score & 0.7825\\
\bottomrule
\end{tabular}
\label{tab:cascade_metrics}
\end{table}
\section{Выводы и заключение}

В ходе работы был разработан и протестирован ML-классификатор переменных звёзд на основе фотометрических данных. Из пяти протестированных алгоритмов лучший результат показал CatBoost с F1-score = 0.7651 (recall = 0.9075, precision = 0.6613). Модель находит около 90\% переменных звёзд, при этом две трети отобранных кандидатов действительно являются переменными. Random Forest дал максимальную точность (precision = 0.8291), но потерял половину переменных объектов (recall = 0.4021). Анализ важности признаков выявил ключевую роль минимальной магнитуды и цветового индекса rpmag. Переменные звёзды демонстрируют характерные провалы блеска и спектральные сдвиги, которые и фиксируются этими параметрами.
Каскадная схема с двойным применением CatBoost немного улучшила результат до F1 = 0.7825 (precision = 0.7241, recall = 0.8511). На тестовой выборке это означает, что из 1773 реальных переменных найдено 1608, а всего классификатор выдал 2430 из 16889 объектов.

Практическая польза разработанного классификатора в том, что он может работать на самых ранних стадиях обзора, когда световых кривых ещё мало для периодограммного анализа. Модель подходит для первичного отбора кандидатов в больших каталогах типа Gaia или LSST, экономя телескопное время и вычислительные ресурсы.

Достигнутый уровень качества (F1 = 0.78) достаточен для использования в качестве первого фильтра в пайплайне обработки данных, где дальше идут более точные методы или экспертная проверка отобранных кандидатов.

\begin{thebibliography}{99}

\bibitem{debosscher2007}
Debosscher J. et al.
Automated classification of variable stars in the SuperWASP survey // 
arXiv:0711.0703, 2007.

\bibitem{naul2018}
Naul B. et al.
Recurrent neural networks for multivariate time series with missing values // 
arXiv:1711.10609, 2018.

\bibitem{li2024}
Li X. et al.
Deep learning approaches for variable star classification // 
arXiv:2504.00347v1, 2024.

\bibitem{armstrong2016}
Armstrong D. J. et al.
K2 Variable Catalogue II: Machine Learning Classification of Variable Stars and Eclipsing Binaries in K2 Fields 0-4 // 
arXiv:1512.01246, 2016.

\bibitem{becker2020}
Becker A. C. et al.
The Zwicky Transient Facility: Science Objectives // 
Monthly Notices of the Royal Astronomical Society, 2020, Vol.~493, No.~2, pp.~2981--3003.

\bibitem{wang2025}
Wang L. et al.
Machine learning methods for imbalanced astronomical datasets // 
arXiv:2504.00347, 2025.

\bibitem{liu2024}
Liu Z. et al.
Hierarchical classification schemes for variable stars // 
Research Notes of the AAS, 2024, Vol.~8, Article~34.

\end{thebibliography}

\end{document}